{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobile Price Range Prediction using Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1N9vZa5tIM9QToyCqskL2Eq7caoUPhJ7V",
      "authorship_tag": "ABX9TyOL9nSILEPoSW8usqEfCXWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rht6226/DL/blob/main/Mobile_Price_Range_Prediction_using_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugx6AK2hN6L8"
      },
      "source": [
        "# Mobile Price Predictor using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59fhHOcuOGsZ"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We will be predicting Mobile data prices based on features.\n",
        "\n",
        "First we need to Load the file from google drive for this, we will be using colab notebook's feature to locally mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWR0BA3HG35V",
        "outputId": "3d317990-ade4-4e69-a121-dc0c388d3338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5B8Afv_Mx8o"
      },
      "source": [
        "The we read the training set.\n",
        "\n",
        "As the training set is in CSV format, we will use pandas for reading it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2S2bM1JIXAh",
        "outputId": "0d199d1c-1305-49b5-e208-290c9cc18ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Training set import\n",
        "trainingSet = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Datasets/MobilePriceRangeDataset/train.csv')\n",
        "trainingSet.head(10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>756</td>\n",
              "      <td>2549</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>905</td>\n",
              "      <td>1988</td>\n",
              "      <td>2631</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0.9</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1263</td>\n",
              "      <td>1716</td>\n",
              "      <td>2603</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>131</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1216</td>\n",
              "      <td>1786</td>\n",
              "      <td>2769</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1821</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1208</td>\n",
              "      <td>1212</td>\n",
              "      <td>1411</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1859</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0.7</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1004</td>\n",
              "      <td>1654</td>\n",
              "      <td>1067</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1821</td>\n",
              "      <td>0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>139</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>381</td>\n",
              "      <td>1018</td>\n",
              "      <td>3220</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1954</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0.8</td>\n",
              "      <td>187</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>512</td>\n",
              "      <td>1149</td>\n",
              "      <td>700</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1445</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>174</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>386</td>\n",
              "      <td>836</td>\n",
              "      <td>1099</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>509</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>93</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>1137</td>\n",
              "      <td>1224</td>\n",
              "      <td>513</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   battery_power  blue  clock_speed  ...  touch_screen  wifi  price_range\n",
              "0            842     0          2.2  ...             0     1            1\n",
              "1           1021     1          0.5  ...             1     0            2\n",
              "2            563     1          0.5  ...             1     0            2\n",
              "3            615     1          2.5  ...             0     0            2\n",
              "4           1821     1          1.2  ...             1     0            1\n",
              "5           1859     0          0.5  ...             0     0            1\n",
              "6           1821     0          1.7  ...             0     1            3\n",
              "7           1954     0          0.5  ...             1     1            0\n",
              "8           1445     1          0.5  ...             0     0            0\n",
              "9            509     1          0.6  ...             0     0            0\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i85LrTLJKhn8"
      },
      "source": [
        "We now need to split the table into two sets for training our model. We will split this table into two different numpy Arrays X and Y.\n",
        "\n",
        "This code will make two arrays X and y. X contains features and y will contain  the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr_YWKaGJnEo"
      },
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "X = trainingSet.iloc[:,:20].values\n",
        "y = trainingSet.iloc[:,20:21].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaW4kksuKtZC"
      },
      "source": [
        "This step is used to normalize the data. Normalization is a technique used to change the values of an array to a common scale, without distorting differences in the ranges of values. \n",
        "\n",
        " **It is an important step**\n",
        "\n",
        " It is mainly required in case the dataset features vary a lot. As in our case, the value of battery power is in the 1000’s and clock speed is less than 3. \n",
        " \n",
        "**So if we feed unnormalized data to the neural network, the gradients will change differently for every column and thus the learning will oscillate**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGuXEtKEKWuS",
        "outputId": "9b4e1c3f-0272-411c-f641-1b328c0ef276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# X after normalisation\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.90259726, -0.9900495 ,  0.83077942, -1.01918398, -0.76249466,\n",
              "       -1.04396559, -1.38064353,  0.34073951,  1.34924881, -1.10197128,\n",
              "       -1.3057501 , -1.40894856, -1.14678403,  0.39170341, -0.78498329,\n",
              "        0.2831028 ,  1.46249332, -1.78686097, -1.00601811,  0.98609664])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrlglu_-Lg8-"
      },
      "source": [
        "Next step is to **one hot encode** the classes. *One hot encoding is a process to convert integer classes into binary values.* \n",
        "\n",
        "Consider an example, let’s say there are 3 classes in our dataset namely 1,2 and 3. Now **we cannot directly feed this to neural network** so we convert it in the form:\n",
        "1- 1 0 0\n",
        "2- 0 1 0\n",
        "3- 0 0 1\n",
        "\n",
        "Now there is one unique binary value for the class. \n",
        "\n",
        "The new array formed will be of shape (n, number of classes), where n is the number of samples in our dataset. We can do this using simple function by sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg78wTkSMEYw",
        "outputId": "ced835ba-7522-4471-8054-a43177db8b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# One Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()\n",
        "\n",
        "# Output after One hot Encoding\n",
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIwsdxLcMZpC"
      },
      "source": [
        "Now our dataset is processed and ready to feed in the neural network.\n",
        "\n",
        "Generally, it is better to *split data into training and testing data.*\n",
        "\n",
        "Training data is the data on which we will train our neural network. Test data is used to check our trained neural network. This data is totally new for our neural network and if the neural network performs well on this dataset, it shows that there is no overfitting.\n",
        "\n",
        "\n",
        "This will split our dataset into training and testing. Training data will have 90% samples and *test data will have 10% samples*. This is specified by the **test_size** argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85cSWGQGNiUU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUwzlehhOXHb"
      },
      "source": [
        "## Building Neural Network\n",
        "\n",
        "Keras is a simple tool for constructing a neural network. It is a high-level framework based on tensorflow, theano or cntk backends.\n",
        "\n",
        "\n",
        "**In our dataset, the input is of 20 values and output is of 4 values. So the input and output layer is of 20 and 4 dimensions respectively.**\n",
        "\n",
        "\n",
        "In our neural network, we are using two hidden layers of 16 and 12 dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taE6DksOOzjx"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=20, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1GkrjPlPsuh"
      },
      "source": [
        "**Sequential** specifies to keras that we are creating model sequentially and the output of each layer we add is input to the next layer we specify.\n",
        "\n",
        "**model.add** is used to add a layer to our neural network. We need to specify as an argument what type of layer we want.\n",
        "\n",
        "The **Dense** is used to specify the fully connected layer. The arguments of Dense are output dimension (Number of hidden units in this layer) which is 16 in the first case, *input dimension which is 20 for input dimension* and the activation function to be used which is relu in this case.\n",
        "\n",
        "The second layer is similar, *we dont need to specify input dimension as we have defined the model to be sequential so keras will automatically consider input dimension to be same as the output of last layer* i.e 16. \n",
        "\n",
        "In the third layer(output layer) the output dimension is 4(number of classes).\n",
        "\n",
        "The output layer takes different activation functions and for the case of multiclass classification, it is **softmax**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVGokO08Q2-g"
      },
      "source": [
        "# Compiling the model by specifying which loss function to be used, which optimizer and which metrics to judge the network on.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCsPFKRwRdmT"
      },
      "source": [
        "Here loss is cross entropy loss. **Categorical_crossentropy** specifies that we have **multiple classes**. The optimizer is Adam. \n",
        "\n",
        "Metrics is used to specify the way we want to judge the performance of our neural network. Here we have specified it to accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwTFit74RpPI"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Training step is simple in keras. **model.fit** is used to train it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPNIZ_OQSpW0"
      },
      "source": [
        "Here we need to specify the input data-> X_train, labels-> y_train, number of epochs(iterations), and batch size.\n",
        "\n",
        "It **returns the history** of model training. **History consists of model accuracy and losses after each epoch**. We will visualize it later.\n",
        "\n",
        "Usually, **the dataset is very big** and we **cannot fit complete data at once** so we use batch size. This **divides our data into batches** each of size equal to batch_size. Now only this number of samples will be **loaded into memory and processed**. Once we are done with one batch it is **flushed from memory** and the next batch will be processed.\n",
        "\n",
        "Let's get to training...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV6L2wnhSk-r"
      },
      "source": [
        "# history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I809UrvIWejt"
      },
      "source": [
        "We can use test data as validation data and can check the accuracies after every epoch. \n",
        "\n",
        "This will give us an insight into overfitting at the time of training only and we can take steps before the completion of all epochs. \n",
        "\n",
        "We can do this by changing fit function as shown below. Now the training step output will also contain validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqDgKDHnXNII",
        "outputId": "49cc63b3-df98-4e25-e282-908aa1dbe43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 1.4413 - accuracy: 0.2539 - val_loss: 1.4075 - val_accuracy: 0.2600\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.4003 - accuracy: 0.2744 - val_loss: 1.3849 - val_accuracy: 0.2800\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.3729 - accuracy: 0.3028 - val_loss: 1.3651 - val_accuracy: 0.3100\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.3465 - accuracy: 0.3350 - val_loss: 1.3447 - val_accuracy: 0.3200\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.3160 - accuracy: 0.3644 - val_loss: 1.3142 - val_accuracy: 0.3700\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.2764 - accuracy: 0.4017 - val_loss: 1.2746 - val_accuracy: 0.3950\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.2280 - accuracy: 0.4467 - val_loss: 1.2254 - val_accuracy: 0.4300\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.1711 - accuracy: 0.4961 - val_loss: 1.1562 - val_accuracy: 0.5100\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.1039 - accuracy: 0.5372 - val_loss: 1.0843 - val_accuracy: 0.5550\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.5856 - val_loss: 1.0020 - val_accuracy: 0.6150\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.9575 - accuracy: 0.6244 - val_loss: 0.9259 - val_accuracy: 0.6350\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.6789 - val_loss: 0.8514 - val_accuracy: 0.6700\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.8103 - accuracy: 0.7311 - val_loss: 0.7781 - val_accuracy: 0.6900\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.7511 - val_loss: 0.7137 - val_accuracy: 0.7550\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.7828 - val_loss: 0.6571 - val_accuracy: 0.7650\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.8128 - val_loss: 0.6066 - val_accuracy: 0.8050\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.8383 - val_loss: 0.5626 - val_accuracy: 0.8050\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.8506 - val_loss: 0.5269 - val_accuracy: 0.8150\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8628 - val_loss: 0.4961 - val_accuracy: 0.8100\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8861 - val_loss: 0.4652 - val_accuracy: 0.8300\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8833 - val_loss: 0.4395 - val_accuracy: 0.8250\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8961 - val_loss: 0.4167 - val_accuracy: 0.8450\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.9050 - val_loss: 0.3950 - val_accuracy: 0.8400\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.9133 - val_loss: 0.3786 - val_accuracy: 0.8600\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.9161 - val_loss: 0.3629 - val_accuracy: 0.8650\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.9256 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9283 - val_loss: 0.3321 - val_accuracy: 0.8800\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9289 - val_loss: 0.3198 - val_accuracy: 0.8800\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9361 - val_loss: 0.3037 - val_accuracy: 0.8800\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9400 - val_loss: 0.2972 - val_accuracy: 0.8850\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9394 - val_loss: 0.2822 - val_accuracy: 0.8950\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9444 - val_loss: 0.2763 - val_accuracy: 0.8950\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9450 - val_loss: 0.2711 - val_accuracy: 0.8850\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9483 - val_loss: 0.2648 - val_accuracy: 0.9050\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9478 - val_loss: 0.2607 - val_accuracy: 0.8900\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9528 - val_loss: 0.2600 - val_accuracy: 0.8900\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9539 - val_loss: 0.2476 - val_accuracy: 0.9200\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9550 - val_loss: 0.2476 - val_accuracy: 0.8950\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9567 - val_loss: 0.2362 - val_accuracy: 0.9150\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9572 - val_loss: 0.2399 - val_accuracy: 0.9050\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9617 - val_loss: 0.2316 - val_accuracy: 0.9050\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9617 - val_loss: 0.2325 - val_accuracy: 0.9050\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9589 - val_loss: 0.2305 - val_accuracy: 0.9100\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9628 - val_loss: 0.2254 - val_accuracy: 0.9150\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9650 - val_loss: 0.2211 - val_accuracy: 0.9200\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9656 - val_loss: 0.2221 - val_accuracy: 0.9200\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9656 - val_loss: 0.2189 - val_accuracy: 0.9300\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.2148 - val_accuracy: 0.9250\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9689 - val_loss: 0.2152 - val_accuracy: 0.9300\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9739 - val_loss: 0.2122 - val_accuracy: 0.9250\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9711 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9700 - val_loss: 0.2158 - val_accuracy: 0.9250\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9728 - val_loss: 0.2119 - val_accuracy: 0.9200\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9700 - val_loss: 0.2075 - val_accuracy: 0.9300\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9744 - val_loss: 0.2029 - val_accuracy: 0.9300\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9756 - val_loss: 0.2043 - val_accuracy: 0.9300\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9772 - val_loss: 0.2068 - val_accuracy: 0.9350\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9761 - val_loss: 0.2027 - val_accuracy: 0.9350\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9744 - val_loss: 0.2066 - val_accuracy: 0.9250\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9750 - val_loss: 0.2009 - val_accuracy: 0.9250\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9800 - val_loss: 0.2046 - val_accuracy: 0.9250\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9783 - val_loss: 0.1992 - val_accuracy: 0.9250\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9800 - val_loss: 0.1994 - val_accuracy: 0.9300\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9789 - val_loss: 0.2027 - val_accuracy: 0.9200\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9817 - val_loss: 0.1993 - val_accuracy: 0.9350\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9817 - val_loss: 0.1960 - val_accuracy: 0.9400\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9817 - val_loss: 0.1935 - val_accuracy: 0.9300\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9806 - val_loss: 0.1987 - val_accuracy: 0.9250\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9839 - val_loss: 0.1964 - val_accuracy: 0.9350\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9850 - val_loss: 0.1938 - val_accuracy: 0.9250\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9850 - val_loss: 0.1935 - val_accuracy: 0.9300\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9861 - val_loss: 0.1906 - val_accuracy: 0.9350\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9839 - val_loss: 0.1938 - val_accuracy: 0.9300\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9867 - val_loss: 0.1895 - val_accuracy: 0.9350\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9850 - val_loss: 0.1891 - val_accuracy: 0.9400\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9844 - val_loss: 0.1899 - val_accuracy: 0.9400\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9850 - val_loss: 0.1885 - val_accuracy: 0.9350\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9889 - val_loss: 0.1895 - val_accuracy: 0.9400\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9878 - val_loss: 0.1902 - val_accuracy: 0.9350\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9861 - val_loss: 0.1855 - val_accuracy: 0.9350\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9883 - val_loss: 0.1893 - val_accuracy: 0.9400\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9900 - val_loss: 0.1880 - val_accuracy: 0.9400\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9922 - val_loss: 0.1845 - val_accuracy: 0.9350\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9917 - val_loss: 0.1865 - val_accuracy: 0.9400\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9917 - val_loss: 0.1863 - val_accuracy: 0.9350\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9950 - val_loss: 0.1881 - val_accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9944 - val_loss: 0.1870 - val_accuracy: 0.9350\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9944 - val_loss: 0.1861 - val_accuracy: 0.9400\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9928 - val_loss: 0.1891 - val_accuracy: 0.9300\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9906 - val_loss: 0.1934 - val_accuracy: 0.9400\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9917 - val_loss: 0.1892 - val_accuracy: 0.9350\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9939 - val_loss: 0.1893 - val_accuracy: 0.9350\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9933 - val_loss: 0.1872 - val_accuracy: 0.9350\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9944 - val_loss: 0.1822 - val_accuracy: 0.9350\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9950 - val_loss: 0.1907 - val_accuracy: 0.9350\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9950 - val_loss: 0.1835 - val_accuracy: 0.9350\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9956 - val_loss: 0.1848 - val_accuracy: 0.9350\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9972 - val_loss: 0.1895 - val_accuracy: 0.9400\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9944 - val_loss: 0.1839 - val_accuracy: 0.9350\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9967 - val_loss: 0.1895 - val_accuracy: 0.9400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E39ZSlgDT0BB"
      },
      "source": [
        "After 100 epochs the neural network will be trained. The training accuracy is reached 99.3 % so our model is trained.\n",
        "\n",
        "Too many Epoch will lead to overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugckUCmPWA94"
      },
      "source": [
        "**Now we can check the model’s performance on test data:**\n",
        "\n",
        "The below step is inverse one hot encoding process. We get integer labels using this step. \n",
        "\n",
        "We then predict on test data using a simple method of keras, model.predict(). \n",
        "\n",
        "It will take the test data as input and will return the prediction outputs as softmax.\n",
        "\n",
        "Then We conver the softmax into label and predict the accuracy by comparing it to the input labels\n",
        "\n",
        "We get an accuracy of 94.0%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQj4ltF1Uolg",
        "outputId": "bc7b9aee-bc61-40eb-fc7f-06041804cde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#Converting predictions to class label\n",
        "pred = list()\n",
        "for i in range(len(y_pred)):\n",
        "    pred.append(np.argmax(y_pred[i]))\n",
        "\n",
        "#Converting one hot encoded test-label to class label\n",
        "test = list()\n",
        "for i in range(len(y_test)):\n",
        "    test.append(np.argmax(y_test[i]))\n",
        "\n",
        "# Predicting Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(pred,test)\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 94.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYb7W633XnV9"
      },
      "source": [
        "## Visualisation\n",
        "\n",
        "Our model is working fine. Now we will visualize training and validation losses and accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8rmjf6-YAgY",
        "outputId": "5e793ad2-da5a-4cd2-a095-08d8843bc80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9bn48c+Tyb5DEiAQIBHZF0Ei4i4urUsVrdpitWprq/ZXr1pre7W3t+V67XJvvW2ttVbrvuJWFRVF61K0IhB2AghhTwgkJJCFkGVmnt8f3wkMIYEEMpkk87xfr3kxZ39ORs9zvsv5HlFVjDHGRK6ocAdgjDEmvCwRGGNMhLNEYIwxEc4SgTHGRDhLBMYYE+EsERhjTISzRGAigojkioiKSHQ71r1BRD7ririM6Q4sEZhuR0Q2i0ijiGS2mL80cDHPDU9kxvROlghMd7UJuLp5QkTGA4nhC6d7aE+JxpiOskRguqtngeuCpq8HngleQUTSROQZESkXkS0i8nMRiQos84jI/SKyS0Q2Ahe3su3jIlIqIiUicp+IeNoTmIi8IiI7RKRKROaJyNigZQki8n+BeKpE5DMRSQgsO11EPheRPSKyTURuCMz/RES+F7SPg6qmAqWgH4rIemB9YN4DgX1Ui8hiETkjaH2PiPxMRDaISE1g+WAReUhE/q/FucwWkR+157xN72WJwHRXXwCpIjI6cIGeATzXYp0HgTTgOOAsXOL4TmDZ94GvAZOAfODKFts+BXiB4wPrfAX4Hu3zLjAc6AcsAZ4PWnY/MBk4FegL/BTwi8jQwHYPAlnARGBZO48HcBlwMjAmML0osI++wAvAKyISH1h2J640dRGQCnwXqAOeBq4OSpaZwHmB7U0kU1X72KdbfYDNuAvUz4HfABcAHwDRgAK5gAdoBMYEbXcz8Eng+0fALUHLvhLYNhroDzQACUHLrwY+Dny/AfisnbGmB/abhrux2gec0Mp69wCvt7GPT4DvBU0fdPzA/s85Qhy7m48LfAlMb2O9NcD5ge+3AnPC/XvbJ/wfq2803dmzwDwgjxbVQkAmEANsCZq3BRgU+D4Q2NZiWbOhgW1LRaR5XlSL9VsVKJ38CrgKd2fvD4onDogHNrSy6eA25rfXQbGJyF3AjbjzVNydf3Pj+uGO9TRwLS6xXgs8cAwxmV7CqoZMt6WqW3CNxhcBf2+xeBfQhLuoNxsClAS+l+IuiMHLmm3DlQgyVTU98ElV1bEc2beA6bgSSxqudAIggZjqgWGtbLetjfkAezm4IXxAK+vsHyY40B7wU+AbQB9VTQeqAjEc6VjPAdNF5ARgNPBGG+uZCGKJwHR3N+KqRfYGz1RVH/Ay8CsRSQnUwd/JgXaEl4HbRCRHRPoAdwdtWwq8D/yfiKSKSJSIDBORs9oRTwouiVTgLt6/DtqvH3gC+L2IDAw02p4iInG4doTzROQbIhItIhkiMjGw6TLg6yKSKCLHB875SDF4gXIgWkR+gSsRNHsM+G8RGS7OBBHJCMRYjGtfeBZ4TVX3teOcTS9nicB0a6q6QVUL2lj8b7i76Y3AZ7hGzycCy/4GzAWW4xp0W5YorgNigdW4+vVXgex2hPQMrpqpJLDtFy2W3wWsxF1sK4H/AaJUdSuuZPPjwPxlwAmBbf6Aa+/Yiau6eZ7Dmwu8B6wLxFLPwVVHv8clwveBauBxICFo+dPAeFwyMAZRtRfTGBNJRORMXMlpqNoFwGAlAmMiiojEALcDj1kSMM0sERgTIURkNLAHVwX2xzCHY7oRqxoyxpgIZyUCY4yJcD3ugbLMzEzNzc0NdxjGGNOjLF68eJeqZrW2rMclgtzcXAoK2upNaIwxpjUisqWtZVY1ZIwxEc4SgTHGRDhLBMYYE+F6XBtBa5qamiguLqa+vj7coYRcfHw8OTk5xMTEhDsUY0wvEbJEICJP4F4MUqaq41pZLrghcC/CvTTjBlVdcjTHKi4uJiUlhdzcXIKGFe51VJWKigqKi4vJy8sLdzjGmF4ilFVDT+FeKNKWC3FveRoO3AQ8fLQHqq+vJyMjo1cnAQARISMjIyJKPsaYrhOyRKCq83CjLLZlOvCMOl8A6SLSntEfW9Xbk0CzSDlPY0zXCWcbwSAOHjq3ODCvNDzhGGNM12v0+qna18SWir1s2rWXspoGRmenMHloX9ISYvD5lU279lK4vYoTctLJzUzq9Bh6RGOxiNyEqz5iyJAhR1i761VUVHDuuecCsGPHDjweD1lZ7gG+hQsXEhsb2+a2BQUFPPPMM/zpT3/qkliNiQT7Gn2U7KkjLtpDUlw0ibEemgvTdQ0+/rVhFx+vLeeLjRUAJMV5SIiNJjrqQIk7KzmOvKwk8jKSGN4/mdHZqcTHePYv9/uVLZV1FG6vonB7NXvqmkiK9ZAYF42qUlbdQFlNPZV1TdQ1eKlr9FHf5Nu/vU+VugYfjT4/rRGBvIwkdlTXU9fotvv5xaP53hnHdfafK6yJoISDXyWYw4HXDB5EVR8FHgXIz8/vdqPkZWRksGzZMgBmzpxJcnIyd9111/7lXq+X6OjW/9T5+fnk5+d3SZzG9CQbymspr2kgKyWOrJQ4UuKiD6karW/yUVRWy+aKvWypqKOorJbC7VUUldXiP8KVIj0xhtOGZRIf46Gu0cveRh/+wEZ+VdaV1fDh2p00+dy8KIFhWcnEx3goq6lnV20jvsD6MR4hPTGWuga3nyiBzGQXd9+kWAamxZMUF01cdNT+hBQlQmJsNEmxHlLioxmSkUhuRhKZKXGsKqli0abdrNpexZkjshg7MJWxA9MY3j+5c//IAeFMBLOBW0VkFnAyUBV4hWCvcMMNNxAfH8/SpUs57bTTmDFjBrfffjv19fUkJCTw5JNPMnLkSD755BPuv/9+3n77bWbOnMnWrVvZuHEjW7du5Y477uC2224L96kYs5+qsruuyd3p7m3c/yZlr1+p2NtAeU0Du+uaGNo3cf+Fa0N5LQs3VbJ06x6S4qLJy3QXvIzkWBJjo0mOi8bnV2obvNQ2eFm0qZJ3VpaydkfNQcdOjotmaEYiuZlJxHqiWL29mqLy2v0XY4DstHjGZKdywdgBHJeVTKPP7+7Gm3w0D7Qc4xEmD+3LxMHpeKIO3+bm9fkp2bOPNaU1rA7c+ftUGTUghX6pcQwJOs+4aFda8PsVhSPu+3BOHZbJqcMyj3r7jgpl99EXgbOBTBEpBn4JxACo6l+BObiuo0W47qPf6Yzj/tdbhazeXt0Zu9pvzMBUfnlJe95rfrDi4mI+//xzPB4P1dXVfPrpp0RHR/OPf/yDn/3sZ7z22muHbLN27Vo+/vhjampqGDlyJD/4wQ/smQHT6eoavSzduofSqtZ7oMV4hKyUOPqlxNPo9TNvfTmffFnGki172qzKaBYltHo3np0WT4PX7xLIYYhA/tA+zLxkDMP7p1Be4xJMyZ59bNq1l1UlVTQ0+RmdncL5Y/ozOjuVvMwkcjMTSYzt3EtatCeKoRlJDM1I4oJxA9q1TdQxJIBwCVkiUNWrj7BcgR+G6vjdwVVXXYXH4+4SqqqquP7661m/fj0iQlNTU6vbXHzxxcTFxREXF0e/fv3YuXMnOTk5XRm26Qaq9jVRVl1PWmIMGUlxh727rKpr4qWCrbxcUEyUwNCMJHIzEqlr9LG5Yi+bd9UBBC7scZTVNLCqpArvkepOWhidncp1pwxlUJ8E+qXE0ycpBk+gniMqSuibFEu/lDiSYqPZWllH4fZq1u2sIS8ziZPy+jIoPWF/vFsq97I7UHde2+Al2tNcTRLN8f2SGZAWf5R/OXM0ekRjcUcczZ17qCQlHWjd/8///E+mTZvG66+/zubNmzn77LNb3SYuLm7/d4/Hg9frDXWY5hgVldXQ4PUzakBqh6sDVpVUMW99OWXV7q63tGofmyvqDrprbq5vHtLXVYsM6ZuIX5W6Rh9l1fXMLdzJviYfU3L7kpYYw+Zde/nnunISYz3kZiRxUm4fokQoq2lgc8Ve0hJiuOnM45iS15fjMpNprUdyfZPP3YnXNuDzK6cOy+zQxTk3M4nczCQu5tAe4WmJMUxITO/Q38mEVq9LBN1VVVUVgwYNAuCpp54KbzDmmPn8ygerd/LkvzaxYJN7XCYlLprJuX0Yk51Kv5Q4slLiqalvYuGmShZurqR6XxOTh/bhpLy+xEV7eG1xMatLq/dvm5UaR/+UeL46tj+5GUkMSIunel8TZTUN7KiqZ0tlHfPWlVNW0wBAfEwUyXExXHJCNtefmsvYgWn741PVY37mZHj/lGPa3vQclgi6yE9/+lOuv/567rvvPi6++OJwh2Naoao0eP3UNfrwB1oWfX5lQ3ktq7dXs3p7NSV79lFe08DO6nr2NvoYlJ7Azy4aRb+UeBZurmThpko+W7/roGqXjKRYpuS5PuEFW3bz8ZdfAjBuUCr/PX0sX5swkD5JbXcxbqm+yUeMJ+qwpQ978NB0RI97Z3F+fr62fDHNmjVrGD16dJgi6nqRdr5HY2+Dt7lDCzEe2d+jo1nl3kb+ua6MlcXVFG6vYt3OGqrrvQf1QGmpf2ocQ/smkZUaR1ZyHFOPy+D8Mf0PuSD7/cruukbKahqIi44iLzPpoAtzRW0D1fVe8kLwYJAxbRGRxaraal91KxGYXmP33kbeXFbCywUHqlzA1bGPHZjGSbl9Gdw3gY/WlvH5hgp8fiU+JopRA1K5YFw2GUmxJMZ5SIzxHLi4iwS6CKaSmRzXxpEPFhUlZCTHkdHG+odbZkw4WCIwPUJdo5fymgbKahoo2e26EW6u2EtZdQN1ja7nybbKfTT6/IwflMZdXxmxvxRQta+Jgi2VPL9gCw1eP0P6JnLzmcdx4bhsRmenEO2x13KYyGaJwHQ7RWW1PPfFFlaXVrMrcPGvbTi495QIDExLIDstnj5JseT0SeScUf24fFIOYwamtrrfBq+PnVUNDO6bYHXoxgSxRGDCQlVZu6OGfxXtosHrJzkumhhPFO+uKuXT9buIjY5iYk46owemcmbgUf1+KXH0S41nYFo8g/smHjTuS3vERXsYkpEYojMypueyRGBCrqymnndWlFJR20htg5eqfU3M31DBjupDn2rtlxLHj88fwbdOHmL16MZ0EUsEptPUNnhZtnUPMR4hKS6aukYfsxZu5a0V22nyKZ4oISnWQ3JcNJOGpDNtZD/OGplFWkIMdY0+6hq99E+NJ8bq7LtedSk01UHGsNAfSxVKl0Ft+YF5A8ZDaouHz3ZvAfVD38O8ja+uEkoWs38gofg0yDkJooL+G2qqh52FkD0BPEHDtfh9Lo6sURAb1INLFUqXu79FXItnKSo3gicW0kL0tL+3EXashAHjIDroRsjvh6IPYOCJkJzV6Ye1RNAJjmUYaoBPPvmE2NhYTj311JDH2tmafH7eW7WDd1aU8vGXZTR4Dx6HJinWwzUnD+W6U4Ye0o0yWHyMh74d6EtvOoEqFC+CLx6GNbNBomD6X2DCVaE5nrcBVv0dFvzVXYCDRUXDmOlw8i3QWAtf/BXWvw8oDDsXpv7A/dt8gd9Z6Paz4mXwtihZZgyHk2+GYefA8heh4Emo2wUp2XDSjTDuClg7BxY+Cnu2uORx4nUw6TrYtgAWPAI7V7oE8a2Xoc9Qt9/Vb8LfbwJfI4z6mot16Km0+mh2R9WWuTgLHofanZDUz8U6/ipY/wEsfMQlofNmwuk/OvbjtWDPEXSy1oah7uxtusv5Fmyu5Gevr2Tdzlr6pcRx0fhszhnVD0+UsLfBi9evnD48k9R4GzSvQ3asdBfCNW+5iw5ATAJ89Vcw8VudcwxVeP1mWPESxKXBid+G7ctgy2dwzs/hjLsOvsCpwr/+CEuegekPuQtgSxUb3MV17TuQe7q7UA6cCDU7oeAJ99lbBpkj4eSbIHuS287f5M51ybPQUOXmJWVB/o0uQSx6DGp3uDtxCbQLefdBdAKc8E13sYxOCMSw3l3Itze//lxgxAUw6iKXhDZ+fCDeIae67Td+AqtngwbeFdBvDIz7Onz+IHji4FuzYMt8eP/nkJPvzn3x01C/B6Lj3TGOla/BlX6OPx/GXOr+HuvfP7A85yT39xwz/eBSTQcc7jkCSwSdrPmiPm3aNO68805qa2vJzMzkqaeeIjs7mz/96U/89a9/JTo6mjFjxvDb3/6WqVOn7i9FPPjgg5xxxhmHPUY4zre2wcvG8lr2NvjY2+Dlw7VlvLhwK4PSE/jFJWM4f3T/Hjnq4mE11sG830HWSBh7+YGi+u4tsOx5d7E6YcaB6oO9u2Dpc+5/6EnfbrsIv/kzWPaCW6+l3Zth63yISXTHTMxw84sXufln/TucfU/770Krit3Fu99ot79m8x+CuT+D0+6AM38Cccnujv3NW2HlyzDuSpj2M1c94muCt38ES5+F2BR30WouOai6i2vzHXxUNOSd6e6sG2uh/zgo/9Jd7Id/9cCdemvxN9TCqtdc0hsz/cDf29voSiylyw+sm5Lt/vaJfQ/dT3NJZ8vnMPqSg6u7ytbCunfhuGkuSQX/nQpfhwETXPwiLu7nr4SqEpckxkyHyx9x8TXWwapXYdf69v0ORxKTCOOvhMzhB+btKoK1b0PuGZAz+ZgPEVmJ4N273R1VZxowHi78bbtWnTlzJklJSbz++uu8+eabZGVl8dJLLzF37lyeeOIJBg4cyKZNm4iLi2PPnj2kp6d32xLB+p01zFq0jYWbKincXnXQ0MKeKOG7p+Vyx3kjSIrrhTWMtWXwwjcP3Fkm9XPVB+Vr4cs5gTpphbhUmHQtNFTDilfcRRLc3eu4K2HqLZB9woH9Ln0e3roNYpMhvpVurrEp7gJ34rchoc+B+d5GdzFe9hyM/4a7Yz0cX6O7sAXf6Z59j0skW7+Apy6GkRfCN5879M7/n/8D8+4PXLy/4hLEpn+6UsIpP4SXroUt/3J/j20L3d8kKQvyv+s+KQOgvsolxVV/d3fRU27qmvaHzlZbBm/+0P2GZ//s4LaHHsaeLO5iDQ0NrFq1ivPPPx8An89HdrZrCJswYQLXXHMNl112GZdddlk4wzysd1eWcufLy/GrMnFwOrdOO56xg9JIjY8hKc5D/9R4+qf20qGCy9bCC1e5xsxvPg8x8e6O99P7IaGvu4s+6Uao2eHqqRc+6i78k66BKTe7uvaFj8CyF2H5C64K4uSbYecqV8I47mz4xjOubrq9omNh+p+hby58dJ+7az+S+DQ45f/BiTe42D/5jbuD3fyZq/e+7C+H3pmLwNl3w+TvwOInYdHjsK8SLv2zS04A337dlRyWPOMukJf91SWm4MbN+DSXNE7p4SPNJ/eDa14JdxQh1/tKBGE2c+ZMPB4Pc+bMYf78+Ycs9/l8zJs3j7feeot3332XlStXct9993WbEoHfrzzw4Xoe+HA9k4ak88i1k+kX7gv+32+G2ET42h86f9+71ruL+cpXoGmfm+drcne435oFg4KK5DU73V18TMLB+6irdFUiLe/w9+1xd8ULH4E9W928Sd9253GU9bwAVG5y9dNHkjniQG8YVfjn/8Inv3b16d/7h+uZciTeBqirgNSBB89XdQ2t6UM7p7HUhJyVCLpYXFwc5eXlzJ8/n1NOOYWmpibWrVvH6NGj2bZtG9OmTeP0009n1qxZ1NbWkpKSQnV1575VrSOq6pqYt76chZsqmb+xgqKyWq6cnMN9l43r8ENbnW73FlgxCxA45daDqxc2fgI7VrkeJVEdiNPvhw0fwYKHoegf7m5+zGWQ5oYJd3f310L6kIO3S+nf+v5aq6cGSEiHU2918a17z1WXnHD1sV84D9edsi0icPa/w8BJLpG1JwmAu8tvmQSa99cnt+NxmG7JEkEIREVF8eqrr3LbbbdRVVWF1+vljjvuYMSIEVx77bVUVVWhqtx2222kp6dzySWXcOWVV/Lmm2+2q7G4M320did3vbKCyr2NJMV6OHFoH2464ziuys/pHsMwLHsBEHcH/fmDcMkf3fx9e+DV77q71a3z4et/c6WGw2modd0JFzziepck94dp/+GqQULQN3u/KA+M6iZDj4/4SrgjMN1QSKuGROQC4AHAAzymqr9tsXwo8ASQBVQC16pq8eH22d2rhrpCZ5xvfZOP3767lqc+38zobDcu/sTB6d1rADa/Dx44ATKOd3Xay16EH61y9bbv/Qy++Iu72/7iYRh0Ilw9yy1rqXKT64LY3D1x0GQ4+QeBnin27IKJDGGpGhIRD/AQcD5QDCwSkdmqujpotfuBZ1T1aRE5B/gN8O1QxWSczbv28oPnl7CmtJrvnpbHTy8YGZ4qoPoqeOprMOGbrgqlpU3/hKpt7iGa7Imu7/aCv7rqlYWPuF4rF/zG9Vl/9Ua4f0TrVUR+b9ADSz+AwSeF+syM6VFCWTU0BShS1Y0AIjILmA4EJ4IxwJ2B7x8Db4QwHgO8t2oHP3llOR6P8MQN+Zwzqo16764w73ewY4Xr7tt/jOtfHmzJsxCf7p7ijImH0V9zd/bFBa7f9Tn/6dYbdTF87wMofANopYQblwoTvtF6XbcxJqSJYBCwLWi6GDi5xTrLga/jqo8uB1JEJENVK4JXEpGbgJsAhgxp0YAX0BnvaO0JjrYqT1X53dwv+csnGzghJ42HrjmRnD4hHInT73cPGjXWumlPHAybdqCL4a4i1yVz/FWuwfe178HN8w6M4VJX6R6mmfwdlwTAddtc85YrKXzlVwfX6w8Y7z7GmA4Ld2PxXcCfReQGYB5QAvharqSqjwKPgmsjaLk8Pj6eiooKMjIyenUyUFUqKiqIj+94d84/fVjEXz7ZwNVTBjPz0rGHvLqxUzXWwes3uYt2sCGnwoznXS+b9//DPZ7/1V+7KqJHz4aXr4fvvOvq7Ve+4h6KmnTtge1z8iHvLNd/f8pNoYvfmAgTykRQAgwOms4JzNtPVbfjSgSISDJwhaq2o4P0wXJyciguLqa8vPzIK/dw8fHx5OR0bOTDFxZs5Q//WMcVJ+bw68vHhzZZ1pbDizPciJDn3wvHn+fmb18Kb98Jj53nHnJa955bntzPfaY/BK9cD/dl4cZuUfewUvaEg/d/9Sz3pKw18hrTaUKZCBYBw0UkD5cAZgAHjZglIplApar6gXtwPYg6LCYmhry8o+hb3QtV1zdxxV8+JyHWw0m5fclMjuN3c9cybWQWv70ihEnA53VDL7z/c/dY/jefdeO8NOs/1vX+efFqeOfH0Pc4N4hWs7GXgTzjqomatdbl8khdRI0xHRayRKCqXhG5FZiL6z76hKoWisi9QIGqzgbOBn4jIoqrGurhz6OH39P/2sz6slomD+3Ds19sodHrZ9KQdB665sRjG+e/qsQN5NVaY+zuzW4ogqpt7iGjG95pfZCsIVPdE63v/tTV90e3ePHMmOnuY4zpUr1iiAnj1NQ3cfr/fMxJuX147PqTaPD6WL+zluP7JR9d91BVN6jYgocPHrysNblnuDv8kRd27ClfY0yXsCEmIsQz87dQta+J2851Q9nGRXsYN6gDA5sFa6yDN25xL+OIS3MPbo274tBxdsCNpJk++ND5xpgewRJBL1Hb4OVvn25k2sgsJuSkH+POygINvktcX/2Tb3Hj1RtjeiVLBL3Es/O3sKeuidvPG3FsOypdDi992yWDGc93nzFyjDEhY4mgFyivaeBvn27krBFZTBx8FKUBvx/Wz3Vj9mz6pxuC+TvvHDwEszGm17JE0MNV1TXx7ccXsK/Rx08vGNnxHajCS9e4rp8pA+HcX7inedsaWtkY0+tYIujBahu8XP/kQjaW7+XxG/IZO/AoGoa/fNclgbPuhjPvOrYXphhjeiRLBD1UfZOP7z9dwMqSKv5yzYmcMfwoxtP3NrgXmGeNsiRgTASzRNADNfn8/L/nl/DFpgp+/40T+OrYAUe3oy8eht2b3DtoLQkYE7EsEfQwPr/yo5eW8dHaMu67bByXT2rnuEPeBvjbue77yTdD3hluGOiRFx06/LMxJqJYIuhBVJX/eH0lb68o5Z4LR3Ht1KHt3/iLh2HnSug7DGbfChIF4oGv3Be6gI0xPYIlgh7k7RWlzFq0jVunHc/NZw078gbNana6u/8RF8LVL8Lmz6DgcRhyysEvgzfGRCRLBD2EqvLIvA0cl5XEned38KGxD+91VUNf/RWIuGqhvDNCE6gxpsexRNBDfLGxklUl1fz68vFERR1mKOmanfDX090wz1NvgdQcWPYcnHa73f0bY1pliaCHeOzTjWQkxfL1EwcdfsUP74V9u6GmFF65wbUFJPWDM+7qkjiNMT2PJYIeoKishg/XlvGj80YcfjjpksXu7v/U2+C8mbBuLix9zr3uMT61q8I1xvQwlgh6gMc+3URcdBTXTh1y8AK/78DY/6rw7t1unKAzf+Lmj7rIfYwx5jAsEXRzZTX1/H1JCVfl55CRHPRGryXPwpy73Athpt4CdZVQvBAu/bPd/RtjOsQSQTf38qJtNPr83Hh64J3MqvDRffDp/TDwRDds9HNXAALZE2HiNWGN1xjT84Q0EYjIBcADuHcWP6aqv22xfAjwNJAeWOduVZ0Typh6Er9feWPRRn4yYAnHbd0FW4ENH8HqN+DE6+Di37vEsPoNWPUanH0PRB3De4mNMREpZIlARDzAQ8D5QDGwSERmq+rqoNV+Drysqg+LyBhgDpAbqph6mgWbKpla/S4/jHkS3mqeK26o6NPvdM8EAEz4hvsYY8xRCGWJYApQpKobAURkFjAdCE4ECjRXaKcB20MYT4/zSsE2pkcvx5+eS9R3AgWlmAR7V4AxplOFsh5hELAtaLo4MC/YTOBaESnGlQb+rbUdichNIlIgIgXl5eWhiLXbqa5v4sNVWzglqpCoEV+FtEHuY0nAGNPJwl2hfDXwlKrmABcBz4rIITGp6qOqmq+q+VlZRzHufg80e9l2JvoKidUGGP6VcIdjjOnFQpkISoDBQdM5gXnBbgReBlDV+UA8kBnCmHqMVwq28fXkQjQ6AXJPC3c4xpheLJSJYBEwXETyRCQWmAHMbrHOVuBcABEZjUsEkVH3cxhrd1SzvHgP0zzLkLwzXbuAMcaESMgSgap6gVuBucAaXO+gQhG5V/hp7V8AABkISURBVEQuDaz2Y+D7IrIceBG4QVU1VDH1FK8WFDPcs5PUfcUw/Pxwh2OM6eVC+hxB4JmAOS3m/SLo+2rA6j2CeH1+3ly+nbsGFEEFlgiMMSEX7sZi08JnRbsor2ngXM9yyBwJfXLDHZIxppezRNDNvL60hAHxXjIqFllpwBjTJSwRdCO1DV7mFu7gp4NXI75G6zZqjOkSNuhcN/LuylKu9M/l8uKnYeAk905hY4wJMUsE3YXfT8LHv+S+mNfQ4V+FK56A6NhwR2WMiQBWNdRN7Pn0Yb629zWWZ1+FzHgR4pLDHZIxJkJYiaCbKF3xCbWaSZ8rHjjw1jFjjOkCViLoBkr27CN612oqk0cwJDMp3OEYYyKMJYJu4HdvLyeP7eSOnRLuUIwxEcgSQZgt3FTJusLFRIuf1CETwh2OMSYCWSIII59f+a+3Cjk5aYeb0X9ceAMyxkQkSwRh9PclxRRur+ZbuTXgiYO+w8IdkjEmAlkiCKO5hTsYmpHI8boFskaCxzpxGWO6niWCMFFVlm7dQ/7QvsjO1dB/bLhDMsZEKEsEYbK1so6KvY2ckq1Qu8MSgTEmbCwRhMmSrbsByE8INBT3GxPGaIwxkcwSQZgs3bqHpFgPQ5o2uhnWY8gYEyYhTQQicoGIfCkiRSJydyvL/yAiywKfdSKyJ5TxdCdLtu7mhMHpRJUVQmIGJPcLd0jGmAgVskQgIh7gIeBCYAxwtYgcVP+hqj9S1YmqOhF4EPh7qOLpTuoavawpreHEIX2guaFYJNxhGWMiVChLBFOAIlXdqKqNwCxg+mHWvxr3Avteb2VxFT6/MiknBcrWWLWQMSasjpgIROQSETmahDEI2BY0XRyY19oxhgJ5wEdtLL9JRApEpKC8vPwoQulelmx1NWCT06rAu88aio0xYdWeC/w3gfUi8r8iMipEccwAXlVVX2sLVfVRVc1X1fysrKwQhdB1lmzdTV5mEunV69wM6zpqjAmjIyYCVb0WmARsAJ4SkfmBO/SUI2xaAgwOms4JzGvNDCKkWqj5QbJJQ9Jh+zJAICtU+dUYY46sXVU+qloNvIqr588GLgeWiMi/HWazRcBwEckTkVjcxX52y5UCpYw+wPwOxt4jFe/ex67aBqYOAAoeh2HnQGxiuMMyxkSw9rQRXCoirwOfADHAFFW9EDgB+HFb26mqF7gVmAusAV5W1UIRuVdELg1adQYwS1X16E+j52h+kOy8HY9BQy189VdhjsgYE+naM8rZFcAfVHVe8ExVrRORGw+3oarOAea0mPeLFtMz2xdq77B06x4mxhbTZ83zcNL3oN/ocIdkjIlw7UkEM4HS5gkRSQD6q+pmVf0wVIH1Vku37uZX8c8jnjQ4+55wh2OMMe1qI3gF8AdN+wLzTAc1eH3k7PiQcY3LYdp/QGLfcIdkjDHtSgTRgQfCAAh8jw1dSL3XmtIaro96h73JQ2Hyd8IdjjHGAO1LBOXBjbsiMh3YFbqQeq9169eRL+vwj/+GvYTGGNNttOdqdAvwvIj8GRDc08LXhTSqXsrz5dtEiZI86Ypwh2KMMfsdMRGo6gZgqogkB6ZrQx5VLzWs/EO2xwxloPUUMsZ0I+2qnxCRi4GxQLwERslU1XtDGFevU11WzARfIQWDv8/AcAdjjDFB2vNA2V9x4w39G65q6CpgaIjj6nV2LnyFKFFixl8W7lCMMeYg7WksPlVVrwN2q+p/AacAI0IbVu8Tv/5tivwDGTb2pHCHYowxB2lPIqgP/FsnIgOBJtx4Q6a9assZVLWEL+JPJzXBet4aY7qX9rQRvCUi6cDvgCWAAn8LaVS9jK55iyj87Mi5MNyhGGPMIQ6bCAIvpPlQVfcAr4nI20C8qlZ1SXS9gd9P06InKfYPoP/xk8IdjTHGHOKwVUOq6se9d7h5usGSQAetmEVs2Qoe9F7OCUP6hDsaY4w5RHvaCD4UkStE7O3qHdZQA/+YSUnSWOZEncGoAanhjsgYYw7RnkRwM26QuQYRqRaRGhGpDnFcvcOn/we1O/lj9HcZN6gPsdFH8+pnY4wJrfa8qjJFVaNUNVZVUwPTdmt7JJUbYf5D1I/5Bq/szObsET3/XcvGmN7piL2GROTM1ua3fFGNaeGj+yAqhvcH3gJLdnDO6H7hjsgYY1rVnu6jPwn6Hg9MARYD54Qkot5AFTZ8DOMuZ84mGJAaz5hsK0QZY7qn9lQNXRL0OR8YB+xuz85F5AIR+VJEikTk7jbW+YaIrBaRQhF5oWPhd1PVJbCvkqb+J/Dp+nLOGd0Pa2s3xnRXRzMofjFwxOEzRcSD63p6fmCbRSIyW1VXB60zHLgHOE1Vd4tI76g/KV0OQKF/KHsbvZxn1ULGmG6sPW0ED+KeJgZXgpiIe8L4SKYARaq6MbCfWcB0YHXQOt8HHlLV3QCqWtb+0Lux0hWA8M7ODOJjyjl1WGa4IzLGmDa1p0RQEPTdC7yoqv9qx3aDcC+xaVYMnNxinREAIvIvwAPMVNX3Wu5IRG4CbgIYMmRIOw4dZjtWoJkjeG99NacNyyQ+xhPuiIwxpk3tSQSvAvWq6gNX5SMiiapa10nHHw6cDeQA80RkfGBIi/1U9VHgUYD8/HxtuZNup3Q5Nf1PYlvxPm45a1i4ozHGmMNq15PFQELQdALwj3ZsVwIMDprOCcwLVgzMVtUmVd0ErMMlhp5rbwVUl1DozwXgnFHWPmCM6d7akwjig19PGfie2I7tFgHDRSRPRGKBGcDsFuu8gSsNICKZuKqije3Yd/e1wzUUf7B7AKOzU8lOSzjCBsYYE17tSQR7ReTE5gkRmQzsO9JGquoFbgXmAmuAl1W1UETuFZFLA6vNBSpEZDXwMfATVa3o6El0K4EeQ2/tzOT04zPCHIwxxhxZe9oI7gBeEZHtuFdVDsC9uvKIVHUOMKfFvF8EfVfgzsCndyhdQUPSIMorEpmSZ4nAGNP9HTERqOoiERkFjAzM+lJVm0IbVg+2YwXFCe5NnvlDbdhpY0z3156X1/8QSFLVVaq6CkgWkf8X+tB6oIYaqChiWdMQRvRPpk+SvZbSGNP9taeN4PvB3TkDD399P3Qh9WA7VgHw0Z4BnJTbN8zBGGNM+7QnEXiCX0oTGDrCbnVbs2MFAAUNg5mSZ4nAGNMztKex+D3gJRF5JDB9M/Bu6ELqwUqXsy+2Lzvr+1giMMb0GO1JBP+OG97hlsD0ClzPIdNS6XI2Rg8jp0+iPT9gjOkx2jMMtR9YAGzGDSR3Du65ABOsrhLdWchn9XlMsfYBY0wP0maJQERGAFcHPruAlwBUdVrXhNbDbPkcQflg3yiutGohY0wPcrgSwVrc3f/XVPV0VX0Q8HVNWD3Qpnl4PQks1+M5yRKBMaYHOVwi+DpQCnwsIn8TkXNxTxab1myaR1H8ONKSEzkuMync0RhjTLu1mQhU9Q1VnQGMwo0DdAfQT0QeFpGvdFWAPUJtGZSv4aOGUeQP7WuvpTTG9CjtaSzeq6ovqOoluKGkl+J6Eplmm+YB8N7eEZwxwt5GZozpWdrzQNl+qrpbVR9V1XNDFVCPtGkejZ5kCjWXM4dnhTsaY4zpkKN5eb1pafOnFMaOIzcxlcF92/OqBmOM6T46VCIwrdizDSo38m7tCM4aYW8jM8b0PJYIjtXmTwGY5x3DWSOtWsgY0/NYIjhWm+axNzqdzZ4hnGzPDxhjeqCQJgIRuUBEvhSRIhG5u5XlN4hIuYgsC3y+F8p4QmLzZxQwhpOPyyI+xhPuaIwxpsNC1lgcGK76IeB8oBhYJCKzVXV1i1VfUtVbQxVHSDXUQNU2FjSdylkjrFrIGNMzhbJEMAUoUtWNqtoIzAKmh/B4Xa9yIwCbdIC1DxhjeqxQJoJBwLag6eLAvJauEJEVIvKqiAxubUcicpOIFIhIQXl5eShiPToVGwDYlzLUhpUwxvRY4W4sfgvIVdUJwAfA062tFHiILV9V87Oyus+dt29XEQBDho+3YSWMMT1WKBNBCRB8h58TmLefqlaoakNg8jFgcgjj6XTVJV+yQ/sw+fjWCjrGGNMzhDIRLAKGi0ieiMQCM4DZwSuISHbQ5KX0sBfeNJatZ7Pai+qNMT1byHoNqapXRG4F5gIe4AlVLRSRe4ECVZ0N3CYilwJeoBK4IVTxhEJi7RbKovOZmm6vpTTG9FwhHWtIVecAc1rM+0XQ93uAe0IZQ6jovj2k+PagmcPCHYoxxhyTcDcW91g7N7vHIdJyRoY5EmOMOTaWCI7StqKVgOsxZIwxPZklgqNUVfwlAEOPHxfmSIwx5thYIjhalRuo8GThibP3DxhjejZLBEdhT10jGQ3F1KXkhjsUY4w5ZpYIjsLiLbvJlR3E9js+3KEYY8wxs0RwFFYWbaaP1NJ38Ohwh2KMMcfMEsFR2LmpEICYrOFhjsQYY46dJYIOqm/y0VTuBpsjwx4mM8b0fJYIOmjJ1t0M1lJUoqBPbrjDMcaYY2aJoIPmb6ggT3agqTkQHRfucIwx5phZIuigzzdUMDqunCirFjLG9BKWCDpgb4OX5dtc1ZC1DxhjegtLBB2waHMlI3Uz8b5ayD4h3OEYY0ynsETQAfM3VHBx9EJUPDDy4nCHY4wxncISQQd8XrSLy2IXIXlnQFJGuMMxxphOYYmgnarqmvDtWMlAXwmMmR7ucIwxptNYIminLzZVcEHUAvf8wKhLwh2OMcZ0mpAmAhG5QES+FJEiEbn7MOtdISIqIvmhjOdYzC/axdc8C9Ehp0FyVrjDMcaYThOyRCAiHuAh4EJgDHC1iIxpZb0U4HZgQahi6Qyl65dwnGwnatxl4Q7FGGM6VShLBFOAIlXdqKqNwCygtcr1/wb+B6gPYSzHpKy6njF7PkYRqxYyxvQ6oUwEg4BtQdPFgXn7iciJwGBVfedwOxKRm0SkQEQKysvLOz/SI/jHmjIuilrAvuyTIaV/lx/fGGNCKWyNxSISBfwe+PGR1lXVR1U1X1Xzs7K6vn5+w9KPGB5VQsKkK7v82MYYE2qhTAQlwOCg6ZzAvGYpwDjgExHZDEwFZne3BuPaBi8nb3+OfZ4U5IQZ4Q7HGGM6XSgTwSJguIjkiUgsMAOY3bxQVatUNVNVc1U1F/gCuFRVC0IYU4ctXryA86SAyjHXQVxKuMMxxphOF7JEoKpe4FZgLrAGeFlVC0XkXhG5NFTH7WwxC/5Ck0TT/7zbwh2KMcaERHQod66qc4A5Leb9oo11zw5lLEejac928qveY3GfizglbUC4wzHGmJCwJ4sPY+cHDxCtPrxTbw13KMYYEzKWCNrSUEvm2ud4nynkT+pW7dfGGNOpLBG0Qbf8i3hfLauzryAh1hPucIwxJmQsEbRh56p/4tUohk48O9yhGGNMSFkiaEPdhs9YQy5fmXhcuEMxxpiQskTQitq6OgbWrmZP5mRS4mPCHY4xxoSUJYJWfP7ZR8RLEwMnTAt3KMYYE3KWCFpRvPxjAI6bdE6YIzHGmNCzRNDC2h3VZFcvpzphEJKaHe5wjDEm5CwRtDBrwVbyo9YRl3dquEMxxpguEdIhJnqa+iYfi5YuJkuq4DhLBMaYyGAlgiAfrN7JqMbVbmLw1PAGY4wxXcQSQZA3lpZwRvwGND4NskaFOxxjjOkSlggCKvc28s915ZwWV4TkTIEo+9MYYyKDXe0C3lmxnSR/DVn7NsEQqxYyxkQOSwQBHyxey7NJD7iJYfYgmTEmclivIaBkYyG/LLuDXM8uuOJxGDQ53CEZY0yXCWmJQEQuEJEvRaRIRO5uZfktIrJSRJaJyGciMiaU8bSqchN9X7iIvlLD7itfgfFXdnkIxhgTTiFLBCLiAR4CLgTGAFe3cqF/QVXHq+pE4H+B34cqnrbogkeI9tby3/3/SOZYqxIyxkSeUJYIpgBFqrpRVRuBWcD04BVUtTpoMgnQEMZzKG8DvmWzmOubzNSTrIHYGBOZQtlGMAjYFjRdDJzcciUR+SFwJxALdO0ob1/OIbphN29yDv833l5Ob4yJTGHvNaSqD6nqMODfgZ+3to6I3CQiBSJSUF5e3mnHbip4lu2aQdbEr5Jq7x0wxkSoUCaCEmBw0HROYF5bZgGXtbZAVR9V1XxVzc/Kyuqc6KqKid70Ea/4zuTqk+0tZMaYyBXKRLAIGC4ieSISC8wAZgevICLDgyYvBtaHMJ6D6NLnEZTCrIsZn5PWVYc1xphuJ2RtBKrqFZFbgbmAB3hCVQtF5F6gQFVnA7eKyHlAE7AbuD5U8RzE76eh4FkW+8Zy3mnWSGyMiWwhfaBMVecAc1rM+0XQ99tDefw2bfqE+NptvOW5jV9OGBiWEIwxpruIvCeL/X687/+Scu1LyomXkxDrCXdExhgTVmHvNdTllj1P9M4V/KbpW3zzlOFHXt8YY3q5yCoR1Ffj+2Amy3Qk0ROu5Ph+KeGOyBhjwi6ySgTzfofsq+DX/uu56wJ78YwxxkAkJYKKDfi/eJhXvGdx2hnnMTA9IdwRGWNMtxAxVUNa+Dr1Gs2T8dfy2lnDwh2OMcZ0GxGTCOakX8Ov9mVxxxVTSYqLmNM2xpgjipiqocQ4D+PGjOWKyTnhDsUYY7qViLk1njayH9NG9gt3GMYY0+1ETInAGGNM6ywRGGNMhLNEYIwxEc4SgTHGRDhLBMYYE+EsERhjTISzRGCMMRHOEoExxkQ4UdVwx9AhIlIObDnKzTOBXZ0YTk8RiecdiecMkXnekXjO0PHzHqqqWa0t6HGJ4FiISIGq5oc7jq4WiecdiecMkXnekXjO0LnnbVVDxhgT4SwRGGNMhIu0RPBouAMIk0g870g8Z4jM847Ec4ZOPO+IaiMwxhhzqEgrERhjjGnBEoExxkS4iEkEInKBiHwpIkUicne44wkFERksIh+LyGoRKRSR2wPz+4rIByKyPvBvn3DH2tlExCMiS0Xk7cB0nogsCPzeL4lIbLhj7Gwiki4ir4rIWhFZIyKnRMhv/aPAf9+rRORFEYnvbb+3iDwhImUisipoXqu/rTh/Cpz7ChE5saPHi4hEICIe4CHgQmAMcLWIjAlvVCHhBX6sqmOAqcAPA+d5N/Chqg4HPgxM9za3A2uCpv8H+IOqHg/sBm4MS1Sh9QDwnqqOAk7AnX+v/q1FZBBwG5CvquMADzCD3vd7PwVc0GJeW7/thcDwwOcm4OGOHiwiEgEwBShS1Y2q2gjMAqaHOaZOp6qlqrok8L0Gd2EYhDvXpwOrPQ1cFp4IQ0NEcoCLgccC0wKcA7waWKU3nnMacCbwOICqNqrqHnr5bx0QDSSISDSQCJTSy35vVZ0HVLaY3dZvOx14Rp0vgHQRye7I8SIlEQwCtgVNFwfm9VoikgtMAhYA/VW1NLBoB9A/TGGFyh+BnwL+wHQGsEdVvYHp3vh75wHlwJOBKrHHRCSJXv5bq2oJcD+wFZcAqoDF9P7fG9r+bY/5+hYpiSCiiEgy8Bpwh6pWBy9T11+41/QZFpGvAWWqujjcsXSxaOBE4GFVnQTspUU1UG/7rQEC9eLTcYlwIJDEoVUovV5n/7aRkghKgMFB0zmBeb2OiMTgksDzqvr3wOydzUXFwL9l4YovBE4DLhWRzbgqv3NwdefpgaoD6J2/dzFQrKoLAtOv4hJDb/6tAc4DNqlquao2AX/H/TfQ239vaPu3PebrW6QkgkXA8EDPglhc49LsMMfU6QJ1448Da1T190GLZgPXB75fD7zZ1bGFiqreo6o5qpqL+10/UtVrgI+BKwOr9apzBlDVHcA2ERkZmHUusJpe/FsHbAWmikhi4L/35vPu1b93QFu/7WzgukDvoalAVVAVUvuoakR8gIuAdcAG4D/CHU+IzvF0XHFxBbAs8LkIV2f+IbAe+AfQN9yxhuj8zwbeDnw/DlgIFAGvAHHhji8E5zsRKAj83m8AfSLhtwb+C1gLrAKeBeJ62+8NvIhrA2nClf5ubOu3BQTXK3IDsBLXo6pDx7MhJowxJsJFStWQMcaYNlgiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsJZIjCmBRHxiciyoE+nDdwmIrnBI0oa0x1EH3kVYyLOPlWdGO4gjOkqViIwpp1EZLOI/K+IrBSRhSJyfGB+roh8FBgL/kMRGRKY319EXheR5YHPqYFdeUTkb4Ex9d8XkYSwnZQxWCIwpjUJLaqGvhm0rEpVxwN/xo16CvAg8LSqTgCeB/4UmP8n4J+qegJuHKDCwPzhwEOqOhbYA1wR4vMx5rDsyWJjWhCRWlVNbmX+ZuAcVd0YGNxvh6pmiMguIFtVmwLzS1U1U0TKgRxVbQjaRy7wgbqXiyAi/w7EqOp9oT8zY1pnJQJjOkbb+N4RDUHffVhbnQkzSwTGdMw3g/6dH/j+OW7kU4BrgE8D3z8EfgD736mc1lVBGtMRdidizKESRGRZ0PR7qtrchbSPiKzA3dVfHZj3b7g3hf0E99aw7wTm3w48KiI34u78f4AbUdKYbsXaCIxpp0AbQb6q7gp3LMZ0JqsaMsaYCGclAmOMiXBWIjDGmAhnicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgI9/8B7mOu02/fo9QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YeAcyOXYtOj",
        "outputId": "489ae120-864c-4b69-885d-a755525bb6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Test'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNUp37TlY7SX"
      },
      "source": [
        "## More testing \n",
        "\n",
        "We will do manual prediction on additional tests to ensure that the model is good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLIu-w9rZJNL",
        "outputId": "60fa9a39-6bdb-4658-8f84-036418dc4c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Load the testing set\n",
        "\n",
        "testingSet = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Datasets/MobilePriceRangeDataset/test.csv')\n",
        "testingSet.head(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1043</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>193</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>226</td>\n",
              "      <td>1412</td>\n",
              "      <td>3476</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>841</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0.8</td>\n",
              "      <td>191</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>746</td>\n",
              "      <td>857</td>\n",
              "      <td>3895</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1807</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0.9</td>\n",
              "      <td>186</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1270</td>\n",
              "      <td>1366</td>\n",
              "      <td>2396</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1546</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>295</td>\n",
              "      <td>1752</td>\n",
              "      <td>3893</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1434</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.5</td>\n",
              "      <td>108</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>749</td>\n",
              "      <td>810</td>\n",
              "      <td>1773</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1464</td>\n",
              "      <td>1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.8</td>\n",
              "      <td>198</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>569</td>\n",
              "      <td>939</td>\n",
              "      <td>3506</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1718</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1.0</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1283</td>\n",
              "      <td>1374</td>\n",
              "      <td>3873</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>833</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.8</td>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1312</td>\n",
              "      <td>1880</td>\n",
              "      <td>1495</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1111</td>\n",
              "      <td>1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.6</td>\n",
              "      <td>101</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>556</td>\n",
              "      <td>876</td>\n",
              "      <td>3485</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1520</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>171</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>1009</td>\n",
              "      <td>651</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  battery_power  blue  clock_speed  ...  talk_time  three_g  touch_screen  wifi\n",
              "0   1           1043     1          1.8  ...          2        0             1     0\n",
              "1   2            841     1          0.5  ...          7        1             0     0\n",
              "2   3           1807     1          2.8  ...         10        0             1     1\n",
              "3   4           1546     0          0.5  ...          7        1             1     0\n",
              "4   5           1434     0          1.4  ...          7        1             0     1\n",
              "5   6           1464     1          2.9  ...          3        1             1     1\n",
              "6   7           1718     0          2.4  ...         10        0             0     0\n",
              "7   8            833     0          2.4  ...         18        0             1     1\n",
              "8   9           1111     1          2.9  ...         10        1             1     0\n",
              "9  10           1520     0          0.5  ...          5        1             0     1\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMg1HMU2Z3K5",
        "outputId": "8b8fc340-69e6-4699-ef8c-93f414ba28da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Normalise\n",
        "\n",
        "testX = testingSet.iloc[:,:20].values\n",
        "sc = StandardScaler()\n",
        "tX = sc.fit_transform(testX)\n",
        "\n",
        "# X after normalisation\n",
        "tX[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.73031962e+00, -4.75451314e-01,  9.68495997e-01,  3.12600690e-01,\n",
              "        9.66558833e-01,  2.10867604e+00, -9.74329379e-01, -1.58126872e+00,\n",
              "       -1.48724678e+00,  1.53553472e+00, -5.80670762e-01,  9.76025990e-01,\n",
              "       -9.26990483e-01,  3.91911646e-01,  1.22937276e+00,  1.15782393e-03,\n",
              "        3.97362775e-01, -1.65335542e+00, -1.76021608e+00,  1.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTAECvwau93",
        "outputId": "73882170-975e-4628-e8e6-b3b6d34ab84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "# Predict\n",
        "\n",
        "y_pred2 = model.predict(tX)\n",
        "\n",
        "#Converting predictions to class label\n",
        "pred2 = list()\n",
        "for i in range(len(y_pred2)):\n",
        "    pred2.append(np.argmax(y_pred2[i]))\n",
        "\n",
        "testingSet[\"Price Class\"] = np.array(pred2)\n",
        "testingSet.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>Price Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1043</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>193</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>226</td>\n",
              "      <td>1412</td>\n",
              "      <td>3476</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>841</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0.8</td>\n",
              "      <td>191</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>746</td>\n",
              "      <td>857</td>\n",
              "      <td>3895</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1807</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0.9</td>\n",
              "      <td>186</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1270</td>\n",
              "      <td>1366</td>\n",
              "      <td>2396</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1546</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>295</td>\n",
              "      <td>1752</td>\n",
              "      <td>3893</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1434</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.5</td>\n",
              "      <td>108</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>749</td>\n",
              "      <td>810</td>\n",
              "      <td>1773</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1464</td>\n",
              "      <td>1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.8</td>\n",
              "      <td>198</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>569</td>\n",
              "      <td>939</td>\n",
              "      <td>3506</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1718</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1.0</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1283</td>\n",
              "      <td>1374</td>\n",
              "      <td>3873</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>833</td>\n",
              "      <td>0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.8</td>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1312</td>\n",
              "      <td>1880</td>\n",
              "      <td>1495</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1111</td>\n",
              "      <td>1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.6</td>\n",
              "      <td>101</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>556</td>\n",
              "      <td>876</td>\n",
              "      <td>3485</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1520</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>171</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>1009</td>\n",
              "      <td>651</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  battery_power  blue  ...  touch_screen  wifi  Price Class\n",
              "0   1           1043     1  ...             1     0            2\n",
              "1   2            841     1  ...             0     0            0\n",
              "2   3           1807     1  ...             1     1            1\n",
              "3   4           1546     0  ...             1     0            3\n",
              "4   5           1434     0  ...             0     1            0\n",
              "5   6           1464     1  ...             1     1            1\n",
              "6   7           1718     0  ...             0     0            2\n",
              "7   8            833     0  ...             1     1            2\n",
              "8   9           1111     1  ...             1     0            1\n",
              "9  10           1520     0  ...             0     1            0\n",
              "\n",
              "[10 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}